{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# plotting options\n",
    "%matplotlib inline\n",
    "np.set_printoptions(linewidth=250)\n",
    "plt.rc('font'  , size=18)\n",
    "plt.rc('figure', figsize=(10, 8))\n",
    "plt.rc('axes'  , labelsize=22)\n",
    "plt.rc('legend', fontsize=16)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "plt.rc('figure', figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rwk7t/Development/dst/courses/coursera_bigdata/course3/week5\n"
     ]
    }
   ],
   "source": [
    "os.chdir('%s/courses/coursera_bigdata/course3/week5' % os.getenv('DST'))\n",
    "pwd = os.getcwd()\n",
    "print(pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/Cellar/apache-spark/1.5.2/libexec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "spark_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "from pyspark import SparkContext, SparkConf, SQLContext, HiveContext\n",
    "\n",
    "myConf = SparkConf().setAppName('TestApp')\\\n",
    "                    .set('spark.executor.memory', '2G')\\\n",
    "                    .set('spark.hadoop.validateOutputSpecs', 'false')\n",
    "\n",
    "sc      = SparkContext(conf=myConf)\n",
    "sc._jsc.hadoopConfiguration().set('textinputformat.record.delimiter', '\\r\\n')\n",
    "sql_ctx = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: bigint]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_ctx.createDataFrame([(\"somekey\", 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Slides walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'A long time ago in a galaxy far far away\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_RDD = sc.textFile('file:%s/testfile1.txt'%pwd)\n",
    "text_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'A', 1),\n",
       " (u'long', 1),\n",
       " (u'time', 1),\n",
       " (u'ago', 1),\n",
       " (u'in', 1),\n",
       " (u'a', 1),\n",
       " (u'galaxy', 1),\n",
       " (u'far', 1),\n",
       " (u'far', 1),\n",
       " (u'away', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_words(line):\n",
    "    return line.split()\n",
    "\n",
    "def create_pair(word):\n",
    "    return (word, 1)\n",
    "\n",
    "pairs_RDD = text_RDD.flatMap(split_words).map(create_pair)\n",
    "pairs_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 'Ryan', 8.5, 'computer science'],\n",
       " [101, 'Bob', 7.1, 'engineering'],\n",
       " [101, 'Carl', 6.2, 'engineering']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = sc.parallelize([\n",
    "    [100, 'Ryan', 8.5, 'computer science'],\n",
    "    [101, 'Bob' , 7.1, 'engineering'     ],\n",
    "    [101, 'Carl', 6.2, 'engineering'     ]\n",
    "])\n",
    "students.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.266666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_grade(row):\n",
    "    return row[2]\n",
    "\n",
    "students.map(extract_grade).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer science', 8.5), ('engineering', 7.1), ('engineering', 6.2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_degree_grade(row):\n",
    "    return (row[3], row[2])\n",
    "\n",
    "students.map(extract_degree_grade).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 7.1), ('computer science', 8.5)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_grade_RDD = students.map(extract_degree_grade)\n",
    "degree_grade_RDD.reduceByKey(max).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- grade: double (nullable = true)\n",
      " |-- degree: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df = sql_ctx.createDataFrame(students, ['id', 'name', 'grade', 'degree'])\n",
    "students_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(grade)=7.266666666666667)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df.agg({'grade': 'mean'}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(degree=u'computer science', max(grade)=8.5),\n",
       " Row(degree=u'engineering', max(grade)=7.1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df.groupBy('degree').max('grade').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|          degree|max(grade)|\n",
      "+----------------+----------+\n",
      "|computer science|       8.5|\n",
      "|     engineering|       7.1|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.groupBy('degree').max('grade').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,LongType,true),StructField(name,StringType,true),StructField(grade,DoubleType,true),StructField(degree,StringType,true)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('id'    , LongType()  , True),\n",
    "    StructField('name'  , StringType(), True),\n",
    "    StructField('grade' , DoubleType(), True),\n",
    "    StructField('degree', StringType(), True),\n",
    "])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+----------------+\n",
      "| id|name|grade|          degree|\n",
      "+---+----+-----+----------------+\n",
      "|100|Ryan|  8.5|computer science|\n",
      "|101| Bob|  7.1|     engineering|\n",
      "|101|Carl|  6.2|     engineering|\n",
      "+---+----+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df = sql_ctx.createDataFrame(students, schema)\n",
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":100, \"name\":\"Alice\", \"grade\":8.5, \"degree\":\"Computer Science\"}\\n{\"id\":101, \"name\":\"Bob\", \"grade\":7.1, \"degree\":\"Engineering\"}\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_json = \"\"\"\\\n",
    "{\"id\":100, \"name\":\"Alice\", \"grade\":8.5, \"degree\":\"Computer Science\"}\n",
    "{\"id\":101, \"name\":\"Bob\", \"grade\":7.1, \"degree\":\"Engineering\"}\n",
    "\"\"\"\n",
    "students_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "with open(\"students.json\", 'w+') as f:\n",
    "    f.write(students_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+---+-----+\n",
      "|          degree|grade| id| name|\n",
      "+----------------+-----+---+-----+\n",
      "|Computer Science|  8.5|100|Alice|\n",
      "+----------------+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_ctx.read.json('file:%s/students.json'%pwd).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/sql/context.py:507: UserWarning: load is deprecated. Use read.load() instead.\n",
      "  warnings.warn(\"load is deprecated. Use read.load() instead.\")\n"
     ]
    }
   ],
   "source": [
    "yelp_df = sql_ctx.load(\n",
    "    source      ='com.databricks.spark.csv',\n",
    "    header      = 'true',\n",
    "    inferSchema = 'true',\n",
    "    path        = 'file:%s/index_data.csv'%pwd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- full_address: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- neighborhoods: string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- review_count: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<useful>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<useful>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df['useful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[useful: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.select('useful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.filter(yelp_df.useful >= 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.filter(yelp_df['useful'] >= 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.filter('useful >= 1').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'exceptions.TypeError'> 'Column' object is not callable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    yelp_df['useful'].agg({'useful':'max'}).collect()\n",
    "except Exception, e:\n",
    "    print type(e), e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[useful: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.select('useful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(useful)=None)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.select('useful').agg({'useful': 'max'}).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.select('id', 'useful').take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+\n",
      "| id|((useful / 28) * 100)|\n",
      "+---+---------------------+\n",
      "+---+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.select('id', yelp_df.useful/28*100).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+\n",
      "| id|cast(((useful / 28) * 100) as int)|\n",
      "+---+----------------------------------+\n",
      "+---+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.select('id', (yelp_df.useful/28*100).cast('int')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|useful_scaled|\n",
      "+---+-------------+\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.select('id', (yelp_df.useful/28*100).cast('int').alias('useful_scaled')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- useful_scaled: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useful_perc_data = yelp_df.select(\n",
    "    yelp_df['id'].alias('uid'), \n",
    "    (yelp_df.useful/28*100).cast('int').alias('useful_scaled')\n",
    ")\n",
    "useful_perc_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ordering by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- useful_scaled: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useful_perc_data = yelp_df.select(\n",
    "    yelp_df['id'].alias('uid'), \n",
    "    (yelp_df.useful/28*100).cast('int').alias('useful_scaled')\n",
    ").orderBy(desc('useful_scaled'))\n",
    "\n",
    "useful_perc_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|uid|useful_scaled|\n",
      "+---+-------------+\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "useful_perc_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined_df = useful_perc_data.join(\n",
    "    yelp_df,\n",
    "    yelp_df.id==useful_perc_data.uid,\n",
    "    'inner'\n",
    ").select(useful_perc_data.uid, 'useful_scaled', 'review_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- useful_scaled: integer (nullable = true)\n",
      " |-- review_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+\n",
      "|uid|useful_scaled|review_count|\n",
      "+---+-------------+------------+\n",
      "+---+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+\n",
      "|uid|useful_scaled|review_count|\n",
      "+---+-------------+------------+\n",
      "+---+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = useful_perc_data.join(\n",
    "    yelp_df,\n",
    "    yelp_df.id==useful_perc_data.uid,\n",
    "    'inner'\n",
    ").cache().select(useful_perc_data.uid, 'useful_scaled', 'review_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+\n",
      "|uid|useful_scaled|review_count|\n",
      "+---+-------------+------------+\n",
      "+---+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = useful_perc_data.join(\n",
    "    yelp_df,\n",
    "    yelp_df.id==useful_perc_data.uid,\n",
    "    'inner'\n",
    ").cache().select(\n",
    "    useful_perc_data.uid, \n",
    "    'useful_scaled', \n",
    "    'review_count'\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### server logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: integer (nullable = true)\n",
      " |-- protocol: string (nullable = true)\n",
      " |-- request: string (nullable = true)\n",
      " |-- app: string (nullable = true)\n",
      " |-- user_agent_major: integer (nullable = true)\n",
      " |-- region_code: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- subapp: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- client_ip: string (nullable = true)\n",
      " |-- user_agent_family: string (nullable = true)\n",
      " |-- bytes: integer (nullable = true)\n",
      " |-- referer: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- extension: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- os_major: integer (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- device_family: string (nullable = true)\n",
      " |-- record: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- os_family: string (nullable = true)\n",
      " |-- country_code3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df = sql_ctx.load(\n",
    "    source      = 'com.databricks.spark.csv',\n",
    "    header      = 'true',\n",
    "    inferSchema = 'true',\n",
    "    path        = 'file:%s/logs.csv'%pwd\n",
    ")\n",
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9410"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+---------+----------------+-----------+------------+--------------------+---------+------+------------------+------+---------------+-----------------+-----+-------+------------+---------+--------------------+--------+------------------+-------------+--------------------+--------------------+--------------------+---------+-------------+\n",
      "|code|protocol|             request|      app|user_agent_major|region_code|country_code|                  id|     city|subapp|          latitude|method|      client_ip|user_agent_family|bytes|referer|country_name|extension|                 url|os_major|         longitude|device_family|              record|          user_agent|                time|os_family|country_code3|\n",
      "+----+--------+--------------------+---------+----------------+-----------+------------+--------------------+---------+------+------------------+------+---------------+-----------------+-----+-------+------------+---------+--------------------+--------+------------------+-------------+--------------------+--------------------+--------------------+---------+-------------+\n",
      "| 200|HTTP/1.1|GET /metastore/ta...|metastore|            null|         00|          SG|8836e6ce-9a21-449...|Singapore| table|1.2931000000000097|   GET|128.199.234.236|            Other| 1041|      -|   Singapore|         |/metastore/table/...|    null|103.85579999999999|        Other|demo.gethue.com:8...|Mozilla/5.0 (comp...|2014-05-04T06:35:49Z|    Other|          SGP|\n",
      "| 200|HTTP/1.1|GET /metastore/ta...|metastore|            null|         00|          SG|6ddf6e38-7b83-423...|Singapore| table|1.2931000000000097|   GET|128.199.234.236|            Other| 1041|      -|   Singapore|         |/metastore/table/...|    null|103.85579999999999|        Other|demo.gethue.com:8...|Mozilla/5.0 (comp...|2014-05-04T06:35:50Z|    Other|          SGP|\n",
      "| 200|HTTP/1.1|GET /search/?coll...|   search|            null|         00|          SG|313bb28e-dd7c-436...|Singapore|      |1.2931000000000097|   GET|128.199.234.236|            Other| 1041|      -|   Singapore|         |/search/?collecti...|    null|103.85579999999999|        Other|demo.gethue.com:8...|Mozilla/5.0 (comp...|2014-05-04T06:35:52Z|    Other|          SGP|\n",
      "| 200|HTTP/1.1|GET /search/?coll...|   search|            null|         00|          SG|ecb47c61-a9e4-4b5...|Singapore|      |1.2931000000000097|   GET|128.199.234.236|            Other| 1041|      -|   Singapore|         |/search/?collecti...|    null|103.85579999999999|        Other|demo.gethue.com:8...|Mozilla/5.0 (comp...|2014-05-04T06:35:53Z|    Other|          SGP|\n",
      "| 200|HTTP/1.1|     HEAD / HTTP/1.1|         |            null|         00|          SG|affdb6b9-3657-4d1...|Singapore|      |1.2931000000000097|  HEAD|128.199.234.236|            Other|  238|      -|   Singapore|         |                   /|    null|103.85579999999999|        Other|demo.gethue.com:8...|Mozilla/5.0 (comp...|2014-05-04T06:35:54Z|    Other|          SGP|\n",
      "+----+--------+--------------------+---------+----------------+-----------+------------+--------------------+---------+------+------------------+------+---------------+-----------------+-----+-------+------------+---------+--------------------+--------+------------------+-------------+--------------------+--------------------+--------------------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|code|count|\n",
      "+----+-----+\n",
      "| 500|    2|\n",
      "| 301|   71|\n",
      "| 302| 1943|\n",
      "| 502|    6|\n",
      "| 304|  117|\n",
      "| 200| 7235|\n",
      "| 400|    1|\n",
      "| 401|   10|\n",
      "| 404|   11|\n",
      "| 408|   14|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.groupBy('code').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|code|count|\n",
      "+----+-----+\n",
      "| 200| 7235|\n",
      "| 302| 1943|\n",
      "| 304|  117|\n",
      "| 301|   71|\n",
      "| 408|   14|\n",
      "| 404|   11|\n",
      "| 401|   10|\n",
      "| 502|    6|\n",
      "| 500|    2|\n",
      "| 400|    1|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.groupBy('code').count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|code|        avg(bytes)|\n",
      "+----+------------------+\n",
      "| 500|            4684.5|\n",
      "| 301|424.61971830985914|\n",
      "| 302| 415.6510550694802|\n",
      "| 502|             581.0|\n",
      "| 304|185.26495726495727|\n",
      "| 200| 41750.03759502419|\n",
      "| 400|               0.0|\n",
      "| 401|           12472.8|\n",
      "| 404|17872.454545454544|\n",
      "| 408|440.57142857142856|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.groupBy('code').avg('bytes').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------------+----------+----------+\n",
      "|code|code|        avg(bytes)|min(bytes)|max(bytes)|\n",
      "+----+----+------------------+----------+----------+\n",
      "| 500| 500|            4684.5|       422|      8947|\n",
      "| 301| 301|424.61971830985914|       331|       499|\n",
      "| 302| 302| 415.6510550694802|       304|      1034|\n",
      "| 502| 502|             581.0|       581|       581|\n",
      "| 304| 304|185.26495726495727|       157|       204|\n",
      "| 200| 200| 41750.03759502419|         0|   9045352|\n",
      "| 400| 400|               0.0|         0|         0|\n",
      "| 401| 401|           12472.8|      8318|     28895|\n",
      "| 404| 404|17872.454545454544|      7197|     23822|\n",
      "| 408| 408|440.57142857142856|         0|       514|\n",
      "+----+----+------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "logs_df.groupBy('code').agg(\n",
    "    logs_df.code,\n",
    "    F.avg(logs_df.bytes),\n",
    "    F.min(logs_df.bytes),\n",
    "    F.max(logs_df.bytes)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- full_address: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- neighborhoods: string (nullable = true)\n",
      " |-- open: string (nullable = true)\n",
      " |-- review_count: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
