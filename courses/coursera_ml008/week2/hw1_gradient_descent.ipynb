{
 "metadata": {
  "name": "",
  "signature": "sha256:02c489388904e7e00de482751d80e4b2cdceeb5bde549b936fad8d2d67a20dd2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Gradient Descent and Linear Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First consider the 1-D case.  Assume that $x$ is our dependent variable (feature) and $y$ is the variable we wish to predict (predictor).  Given a set of $m$ observations of ($x$, $y$) training values, we wish to find a model that predicts the data.  The linear model uses parameters $\\theta_0$ and $\\theta_1$ to construct a linear hypothesis:\n",
      "\n",
      "\\begin{align}\n",
      "h_{\\theta}(x) &= \\theta_0 + \\theta_1 x_1 \\\\\n",
      "&= \\theta_0 x_0 + \\theta_1 x_1 \\\\\n",
      "&= \\boldsymbol{\\theta}^T\\ {\\bf x} \\\\\n",
      "\\end{align}\n",
      "\n",
      "In order to find an optimum model, we minimize the \"cost function\", $J(\\theta)$, w.r.t. $\\theta$ where\n",
      "\n",
      "$$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right)^2 $$.\n",
      "\n",
      "\n",
      "The goal of regression is to find an optimum fit for a dataset using a linear model.  Here we are summing over the \"training set\" of $m$ observations.\n",
      "\n",
      "Gradient descent is a numerical method to find that minimum if $J(\\theta)$ by incrementally moving towards the the minimum of the $\\theta$ parameter space.  An assumpution of this method is that the model is convex in parameter space.  This is done by walking to the minimum by taking steps defined by:\n",
      "\n",
      "\\begin{align}\n",
      "{\\bf \\theta} &\\leftarrow {\\bf \\theta} - \\alpha \\nabla J(\\theta) \\\\\n",
      "\\end{align}\n",
      "In index notation, \n",
      "\\begin{align}\n",
      "\\theta_f &\\leftarrow \\theta_f - \\alpha \\sum_{f=1}^{N_f} \\frac{\\partial}{\\partial \\theta_f} J(\\theta)\n",
      "\\end{align}\n",
      "where\n",
      "\\begin{align}\n",
      "\\frac{\\partial}{\\partial \\theta_f} J(\\theta) &=\n",
      "\\frac{1}{m} \\sum_{i=1}^{m} \\left(  \\sum_f \\theta_f x_f^{(i)} - y^{(i)} \\right) \\sum_{f'} \\frac{\\partial \\theta_{f'}}{\\partial \\theta_f} x_{f'}^{(i)} \\\\\n",
      "&= \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sum_f \\theta_f x_f^{(i)} - y^{(i)} \\right) \\sum_{f'} \\delta_{ff'} x_{f'}^{(i)} \\\\\n",
      "&= \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sum_f \\theta_f x_f^{(i)} - y^{(i)} \\right) x_{f}^{(i)} \\\\\n",
      "&= \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\boldsymbol{\\theta} \\cdot {\\bf x}^{(i)} - y^{(i)} \\right) x_{f}^{(i)} \\\\\n",
      "\\end{align}\n",
      "\n",
      "where ${\\bf x}^{(i)} = (x_0^{(i)}, x_1^{(i)})$ for the $i^{th}$ datum.  \n",
      "\n",
      "## Implementation details\n",
      "\n",
      "When computing gradient descent in a program such as MATLAB or python, it is customary to represent the data as a Matrix.  The convention that we pick is the training dimension $(i)$ will be denoted by rows and the feature dimension $(j)$ will be determined by columns.  This gives a matrix of the form:\n",
      "\n",
      "\\begin{align}\n",
      "{\\bf X} = \n",
      "\\left( \n",
      "\\begin{array}{ccc}\n",
      "1 & x_1^{(1)}\\\\\n",
      "1 & x_1^{(2)}\\\\\n",
      "\\vdots & \\vdots \\\\\n",
      "1 & x_1^{(m)}\\\\\n",
      "\\end{array} \n",
      "\\right)\n",
      "\\end{align}\n",
      "\n",
      "For convenience, we denote by $x_0^{(i)} = 1$:\n",
      "\n",
      "\\begin{align}\n",
      "{\\bf X} = \n",
      "\\left( \n",
      "\\begin{array}{ccc}\n",
      "x_0^{(1)} & x_1^{(1)}\\\\\n",
      "x_0^{(2)} & x_1^{(2)}\\\\\n",
      "\\vdots & \\vdots \\\\\n",
      "x_0^{(m)} & x_1^{(m)}\\\\\n",
      "\\end{array} \n",
      "\\right)\n",
      "\\end{align}\n",
      "\n",
      "Or you can think of each row as vector representing the $i^{th}$ data point.\n",
      "\n",
      "\\begin{align}\n",
      "{\\bf X} = \n",
      "\\left( \n",
      "\\begin{array}{c}\n",
      "-\\ {{\\bf x}^{(1)} }^T - \\\\\n",
      "-\\ {{\\bf x}^{(2)} }^T - \\\\\n",
      "\\vdots  \\\\\n",
      "-\\ {{\\bf x}^{(m)} }^T - \\\\\n",
      "\\end{array} \n",
      "\\right)\n",
      "\\end{align}\n",
      "\n",
      "In vectorized notation (.i.e. MATLAB or numpy), we must transpose the ${\\bf X}$ matrix so that the columns are now vectors in feature space and the rows are vectors in training dataset space.  \n",
      "In short, $h_{\\theta}(\n",
      "\n",
      "\\begin{align}\n",
      "h_{\\theta}({\\bf X}) \n",
      "&= \\left( \n",
      "\\begin{array}{c}\n",
      "\\theta_0 x_0^{(1)} + \\dots +  \\theta_n x_n^{(1)} \\\\\n",
      "\\theta_0 x_0^{(2)} + \\dots +  \\theta_n x_n^{(2)} \\\\\n",
      "\\vdots \\\\\n",
      "\\theta_0 x_0^{(m)} + \\dots +  \\theta_n x_n^{(m)} \\\\\n",
      "\\end{array}\n",
      "\\right) \\\\\n",
      "&= \\left( \n",
      "\\begin{array}{ccc}\n",
      "x_0^{(1)} & \\dots  & x_n^{(1)} \\\\\n",
      "x_0^{(2)} & \\dots  & x_n^{(2)} \\\\\n",
      "          & \\vdots &           \\\\\n",
      "x_0^{(m)} & \\dots  & x_n^{(m)} \\\\\n",
      "\\end{array}\n",
      "\\right)\n",
      "\\left( \n",
      "\\begin{array}{c}\n",
      "\\theta_0\\\\\n",
      "\\theta_1\\\\\n",
      "\\vdots \\\\\n",
      "\\theta_n\\\\\n",
      "\\end{array}\n",
      "\\right) \\\\\n",
      "&= {\\bf X}\\ {\\bf \\theta}\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we can \"vectorize\" the cost function with (note: the square is \"element by element\"):\n",
      "\n",
      "\\begin{align}\n",
      "J(\\theta) &= \\frac{1}{2m} \\sum_{i=0}^{m}\\left[\\left({\\bf X}\\ {\\bf \\theta} - {\\bf y}\\right)_i^2\\right] \\\\\n",
      "&= \\frac{1}{2m} \\left[\\left({\\bf X}\\ {\\bf \\theta} - {\\bf y}\\right)^T\\left({\\bf X}\\ {\\bf \\theta} - {\\bf y}\\right) \\right]\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1-D example\n",
      "\n",
      "Implement a 1-D linear regression with one variable to predict profits for a food truck.  You want to predict profits based on the size of the population of a city.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setup Notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setup notebook\n",
      "import itertools as it\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.stats as st\n",
      "from IPython.display import display, Math, Latex\n",
      "import os\n",
      "os.chdir('%s/courses/coursera_ml008/week2' % os.getenv('DST'))\n",
      "print(os.getcwd())\n",
      "\n",
      "# plotting options\n",
      "np.set_printoptions(precision=4)\n",
      "plt.rc('font'  , size=18)\n",
      "plt.rc('figure', figsize=(10, 8))\n",
      "plt.rc('axes'  , labelsize=22)\n",
      "plt.rc('legend', fontsize=16)\n",
      "\n",
      "np.set_printoptions(precision=4)\n",
      "plt.rc('figure', figsize=(10, 8))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/rwk7t/Development/dst/courses/coursera_ml008/week2\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('ex1data1.txt', names=['population', 'profit'])\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>population</th>\n",
        "      <th>profit</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 6.1101</td>\n",
        "      <td> 17.5920</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 5.5277</td>\n",
        "      <td>  9.1302</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 8.5186</td>\n",
        "      <td> 13.6620</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 7.0032</td>\n",
        "      <td> 11.8540</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5.8598</td>\n",
        "      <td>  6.8233</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "   population   profit\n",
        "0      6.1101  17.5920\n",
        "1      5.5277   9.1302\n",
        "2      8.5186  13.6620\n",
        "3      7.0032  11.8540\n",
        "4      5.8598   6.8233"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "construct the $\\bf{X}$ and $\\bf{y}$ matrices:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.insert(loc=0, column='constant', value=np.ones(df.population.shape))\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>constant</th>\n",
        "      <th>population</th>\n",
        "      <th>profit</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 6.1101</td>\n",
        "      <td> 17.5920</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 5.5277</td>\n",
        "      <td>  9.1302</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 8.5186</td>\n",
        "      <td> 13.6620</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 7.0032</td>\n",
        "      <td> 11.8540</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1</td>\n",
        "      <td> 5.8598</td>\n",
        "      <td>  6.8233</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   constant  population   profit\n",
        "0         1      6.1101  17.5920\n",
        "1         1      5.5277   9.1302\n",
        "2         1      8.5186  13.6620\n",
        "3         1      7.0032  11.8540\n",
        "4         1      5.8598   6.8233"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.matrix(df.as_matrix(['constant', 'population']))\n",
      "X[0:5,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "matrix([[ 1.    ,  6.1101],\n",
        "        [ 1.    ,  5.5277],\n",
        "        [ 1.    ,  8.5186],\n",
        "        [ 1.    ,  7.0032],\n",
        "        [ 1.    ,  5.8598]])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = X[:,1]\n",
      "x[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "matrix([[ 6.1101],\n",
        "        [ 5.5277],\n",
        "        [ 8.5186],\n",
        "        [ 7.0032],\n",
        "        [ 5.8598]])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.matrix(df.as_matrix(['profit']))\n",
      "y[0:5,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "matrix([[ 17.592 ],\n",
        "        [  9.1302],\n",
        "        [ 13.662 ],\n",
        "        [ 11.854 ],\n",
        "        [  6.8233]])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "plot it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, y,'rx')\n",
      "plt.ylabel('profit in $10k')\n",
      "plt.xlabel('population in 10k')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAIECAYAAACOgoO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYZGV59/HvHRQRUTouiQYJMy7IGxCMS0Q7wohR1EGN\nJupLUBNX4hAN8QWMjuAgdFTGRKNBxRWNuEASNdIxuNFBGzFCzCBeMW7dEHejUwIii879/nFO0dU1\nVd1dXfup7+e6+jpTp87yVFFU//pZIzORJElS9fzKsAsgSZKk/jDoSZIkVZRBT5IkqaIMepIkSRVl\n0JMkSaoog54kSVJFGfQkSZIqaqSCXkQcGBGviojLIuKHEXFtRHwpIl4eEXs3HbstIna1+XnJsF6D\nJEnSqLjNsAvQ5DnAFuCjwN8DtwBHAWcCT4uIwzPzxqZzTgT+t2nfFf0uqCRJ0qgbtaB3ATCTmdc1\n7HtbRHwd2Ao8Fzi76ZyPZOY1gyqgJEnSuBipptvMvKIp5NWdX24PbvFcRMSdImLUQqskSdJQjVTQ\nW8E9y+0PWjx3JVADfh4R8xHx2MEVS5IkaXRFZg67DCuKiD2AzwIPAg7JzK+X+/8cOAi4FNhZ/vtE\n4B7AczLzPcMpsSRJ0mgYh6D3JuAE4GWZ+dpVjr0zcBWwF7B/Zv5sAEWUJEkaSSPdry0izqAIeees\nFvIAMvMnEfFWYBvwcOCTTdcb7VQrSZLUIDOjm/NHNuhFxDaKkbbvyswXdnDq1eX2Lq2eHPUaTI2O\nbdu2sW3btmEXQ2PAz4o64edFaxXRVcYDRnQwRhnyTgPOzczndXj6fcttq4EbkiRJE2Pkgl5EnEYR\n8t6bmc9pc8weEbFvi/37Ay+kmED50r4WVJIkacSNVNNtRJxA0b/uGuDTEfGMpkO+n5mfAu4ILETE\nh4GvUoy6vR/wPGBv4NjMvGlgBVclbdq0adhF0Jjws6JO+HnRII3UqNuIeDfwrPrDFofMZeZREbEn\nxQoZD6WYY28f4EfAPHBWZl7e5vo5Sq9XkiSpnYjoejDGSAW9fjPoSZKkcdGLoDdyffQkSZLUGwY9\nSZKkijLoSZIkVZRBT5Ik9d7sLNRqy/fVasV+DYxBT5Ik9d70NGzduhT2arXi8fT0cMs1YRx1K0mS\n+qMe7k4+GbZvh5kZmJoadqnGhtOrdMigJ0nSgC0uwsaNsLAAGzYMuzRjxelVJEnS6KrVipq8hYVi\n29xnT31n0JMkSb1Xb7admSlq8mZmlvfZ00DYdCtJknpvdrYYeNHYJ69Wg/l52Lx5eOUaI/bR65BB\nT5IkjQv76EmSJKktg54kSVJFGfQkSZIqyqAnSZJUUQY9SZKkijLoSZIkVZRBT5IkqaIMepIkSRVl\n0JMkSaoog54kSVJFGfQkSZIqyqAnSZJUUQY9SZKkijLoSZIkVZRBT5IkqaIMepKkyTE7C7Xa8n21\nWrFfqiCDniRpckxPw9atS2GvViseT08Pt1xSn0RmDrsMAxMROUmvV5LUQj3cnXwybN8OMzMwNTXs\nUkm7iQgyM7q6xiQFH4OeJAmAxUXYuBEWFmDDhmGXRmqpF0HPpltJ0mSp1YqavIWFYtvcZ0+qEIOe\nJGly1JttZ2aKmryZmeV99qSKselWkjQ5ZmeLgReNffJqNZifh82bh1cuqQX76HXIoCdJksaFffQk\nSZLUlkFPkiSpogx6kiRJFWXQkyRJqiiDniRJUkUZ9CRJGqbZ2d3n8avViv1Slwx6kiQN0/T08kmb\n65M6T08Pt1yqBOfRkyRp2Orh7uSTi2XZZmaWT+qsieSEyR0y6EmSRtbiImzcWKzBu2HDsEujEeCE\nyZIkVUGtVtTkLSwUW9feVY8Y9CRJGqZ6s+3MTFGTNzOzvM+e1AWbbiVJGqbZ2WLgRWOfvFoN5udh\n8+bhlUtDZx+9Dhn0JEnSuLCPniRJktoy6EmSJFWUQU+SJKmiDHqSJI0Cl0JTHxj0JEkaBS6Fpj5w\n1K0kSaPCpdDUwOlVOmTQkySNPJdCU8npVSRJqhKXQlOPGfQkSRoFLoWmPrDpVpKkUeBSaGpiH70O\nGfQkSdK4sI+eJEmS2jLoSZIkVZRBT5IkqaJGKuhFxIER8aqIuCwifhgR10bElyLi5RGxd4vj7xcR\nH4mIn0TE9RFxSUQ8chhllyRJGjUjNRgjIl4DbAE+ClwG3AIcBTwNuBI4PDNvLI+9N/DvwM3AG4Br\ngecDhwCPy8xPt7i+gzEkSdJYqNyo24h4EPC1zLyuaf8ZwFbgRZl5drnvfODJwIMy88py3x2ArwA3\nZuZBLa5v0JMkSWOhcqNuM/OK5pBXOr/cHgy3BronAnP1kFee/zPgHcCBEfGQfpdXkiRplI1U0FvB\nPcvtD8rtocCewOdbHPuFcvvgfhdKkiRplI180IuIPYBTKfrrvb/c/Rvl9jstTqnv26/PRZMkSRpp\ntxl2AdbgDcDhwMsy8+vlvvoI3JtaHH9j0zGSJEkTaaSDXjkI4wTgnMx8bcNTN5Tb27U4ba+mY5bZ\ntm3brf/etGkTmzZt6rqckiRJ3Zqbm2Nubq6n1xypUbeNImIbcBrwrsx8XtNzDwPmgTMz87Sm5x4N\nXASckJlvaXrOUbeSJGksVG7UbV1DyDu3OeSVvkzRbPvwFs8dXm4v70/pJEmSxsPI1ehFxGnANuC9\nmfknKxx3PvAU4IEN8+jtQzGP3s+dR0+SJI2zKk6YfALwJuAaipG2zYX7fmZ+qjy2vjLGLcDrgeso\nVsY4GNicmZ9scX2DniRJGgtVDHrvBp5Vf9jikLnMPKrh+IOA1wBHUsyrdwWwLTM/0+b6Bj1JkjQW\nKhf0+s2gJ0mSxkVlB2NIkiSpewY9SZKkijLoSZIkVZRBT5IkqaIMepIkSRVl0JMkSaoog54kSVJF\nGfQkSZIqyqAnSZJUUQY9SZKkijLoSZIkVZRBT5IkqaIMepIkSRVl0JMkSaoog54kSVJFGfQkSZIq\nyqAnSZJUUQY9SZKkijLoSZIkVZRBT5IkqaIMepIkSRVl0JMkadLMzkKttnxfrVbsV6UY9CRJmjTT\n07B161LYq9WKx9PTwy2Xei4yc9hlGJiIyEl6vZIktVUPdyefDNu3w8wMTE0Nu1RqEBFkZnR1jUkK\nPgY9SZIaLC7Cxo2wsAAbNgy7NGrSi6Bn060kSZOoVitq8hYWim1znz1VgkGvn+zsKkkaRfVm25mZ\noiZvZmZ5nz1VhkGvn+zsKkkaRfPzy/vkTU0Vj+fnh1su9Zx99PrNzq6SJGkdHIzRoaENxrCzqyRJ\n6pCDMcaBnV0lSdKQGPT6yc6ukiRpiGy67afZ2WLgRWOfvFqt6Oy6efPgyiFJksaOffQ65ITJkiRp\nXNhHT5KkTjnHqSaIQU+SNFmc41QTxKZbSdLkcY5TjQH76HXIoCdJupVznGrE2UdPkqT1cI5TTQiD\nniRpsjjHqSaITbeSpMniHKcaE/bR65BBT5IkjQv76EmSJKktg54kSVJFGfQkSZIqyqAnSZJUUQY9\nSZKkijLoSZIkVZRBT5IkqaIMepIkSRVl0JMkSaoog54kSVJFGfQkSZIqyqAnSZJUUQY9SZKkijLo\nSZIkVZRBT5IkqaIMepKqa3YWarXl+2q1Yr8kTQCDnqTqmp6GrVuXwl6tVjyenh5uuSRpQCIzh12G\ngYmInKTXK4mlcHfyybB9O8zMwNTUsEslSauKCDIzurrGqAWfiHgZ8EDgQcAG4OrM3Njm2G3AaW0u\ndVJm/k3T8QY9aRItLsLGjbCwABs2DLs0krQmvQh6t+lVYXpoBvgx8B/AvsBaktmJwP827buix+WS\nNI5qtaImb2HBGj1JE2cUg969MnMRICKuAvZewzkfycxr+loqSeOn3mxbD3czM8sfS1LFjdxgjHrI\n61BExJ0iYhSDq6RhmZ9fHurqYW9+frjlkqQBGbmgt05XAjXg5xExHxGPHXaBJI2AzZt3r7mbmir2\nS9IEGPcasJ3AOcCl5b8PouivNxsRz8nM9wyzcJIkScM0cqNuG9X76GXmvTo4587AVcBewP6Z+bOG\n5xx1K0mSxkJVR912JTN/EhFvBbYBDwc+2fj8tm3bbv33pk2b2LRp0wBLJ0mS1Nrc3Bxzc3M9vWbl\navTK8/4YeDfwR5n5wYb91uhJkqSx0IsavTUPxoiIAzo49onrK07P3Lfc/mCopZC0nGvPStJAdTLq\n9l8j4ldXOygijgY+tP4irU1E7BER+7bYvz/wQooJlC/tdzkkdcC1ZyVpoNbcdBsRu4DPAb+XmTe3\nOWYTMAvskZl7ratAEc8E6rWHLwJuC9SXMlvMzPeVx00BC8CHga9SjLq9H/A8ikmWj83Mf2y6tk23\n0rC59qwkrclA17qNiNcBLwH+ITOf1uL5hwGfAG4HPDUzP7quAkVcDBxZPqwXrv4i5zLzqPK4PYGz\ngYcC9wT2AX4EzANnZeblLa5t0JNGgWvPStKqBh30Avgg8FTg9Zn5/xqeexDwaYqw9YzGARCjxKAn\njQBr9CRpTQY6GKNMSM+iqDH7i4j487IQ9wcuAu4IPH9UQ56kEdC49uyGDUtrzzYP0JAk9UTH06uU\nExLPA/cBXgacBPwa8KLMPLvnJewha/SkIZudLQZeNNbg1WrF2rMuSyZJywy06bbpxhuAyygCHsBL\nM3N7NwUZBIOeJEkaF30NehHxm6uc+xDgA8B7gVc1P5mZ13RTsH4w6EmSpHHR76C3i6VRr23PL7fZ\ntC8zc49uCtYPBj1JkjQu+r3WbTc1cqYpSZKkIRvptW57zRo9SZI0LgY6vYokSZLGi0FPkiSpolbq\no3eriNgXeDzwAGAjxeTIANcBi8CXgNnMvLYPZZQkSdI6rBj0IuL2wAywBdhzlWvdFBFvBrZm5o09\nKp+qwolyJUkauJWmV9kTmAMOpxhFeylwOcVo3OvLw/YB9gd+B3gYxdQqlwFHZuYt/Sz4ejgYY4ga\nl76amtr9sSRJWqbf8+i9HDgTuAR4dmYurFKYewHvAo6gqNV7dTcF6weD3pC5mL0kSWvW76D3ZYol\nzu6VmT9bY4H2Ab4J/DAz799NwfrBoDcCFhdh40ZYWCgWtVd12DwvST3V7+lV7gXMrTXkAWTm9cC/\nledKy9VqRU3ewkKxrdWGXSL10vR0UWNb/+9ar8Gdnh5uuSRpgq0U9G4CfnUd15wqz5WWNPbJ27Ch\n2DaGAo2/qaml/66Li/bBlKQRsFLT7SeATcB0Zn5xTReLeAjFoI2LM/MxvSpkr9h0O0Q2600Om+cl\nqSf63XT7NxTTr3wmIl4RERtXKMi9IuJU4GJgD+CvuymUKmjz5t1rdqamDHlVY/O8JI2UFde6jYhT\ngNeUDxP4CcX0KvV+e3cAfhO4M8XUKgn8ZWZu71eBu2GNntRHTqEjST3V11G3DTd5MPCXwOOA27c5\n7EbgX4DXZObl3RSonwx6Uh/ZPC9JPTWQoNdwsz2B+1EsgbZPuft6YAH46ihOkNzMoCdJksbFQINe\nFRj0JEnSuOj3YAxJkiSNsZ4HvYi4e0T8Zq+vK0mSpM70o0bvwxT99iRJkjRE/Qh6Uf5IkiRpiPrV\nR88RD5IkSUN2m3ZPRMT/o/PAFsDduyqRJEmSemKltW53dXHdzMw9uji/L5xeRZIkjYteTK/StkYP\n2EXRtPv3dFazt5liSTRJkiQN0Uo1elcCBwO/lZn/veYLRlwGPMQaPUmSpPXr94TJX6Toc/fgbm4g\nSZKk4Vgp6F1ebh+0jus6vYokSdKQrRT0LgReAsx1eM0nA/dab4GkNZudhVpt+b5ardgvSZLaB73M\n/J/MfENm/nMnF8zM72XmYtclk1YzPQ1bty6FvVqteDw9Pdxyqdr8A0PSGOnXhMlSa738JTk1BTMz\nRbhbXCy2MzPFfqlf/AND0hhpO+q2ihx1OwLqvxTrgaz58XosLsLGjbCwABs29LK0Umv1z+3JJ8P2\n7f6BIakv+j3qdq2FiIi4f0Q8OCL26vZ66tAoNyO1KhvAEUf0rhauVit+0S4sFNtW95N6bWqqCHkb\nNxZbQ56kEbVq0IuI/SLiqIjYbYBFRPw28A3gP4F/B34YESf0vphqa5SbkdqV7eije/NLsrE2cMOG\npWZcw576zT8wJI2JtdTonQJ8EjiwcWdE3B74KLAR+BHwZeAOwBsj4nE9LqfaGeV+au3KBr35JTk/\nv/y11u83P9+T4kst+QeGpDGyah+9iLgc2A/YLzN3Nex/LvB2ihD4hMy8OSKeQBH+LsrMkQt7le6j\nN8r91BrLNjXV+z560iDNzha11Y2f11qt+ANj8+bhlUtS5Qyqj95+wOWNIa9U/0bbmpk3A2Tmxyjm\n3XtIN4VSh0a5Gam5bBddZC2cxtvmzbv/UTI1ZciTNJJWWuv2leU/TwWuAv6JYsWLLLcnAHcBzij3\n1R0NPBQ4vX58Zr6qH4XvVCVr9PoxinUSyiZJ0ojrRY3eSkHv3PKfzwQWgM82PH1H4CnANcDFTace\nCjwAeC9LQe/Z3RSyVyoZ9Ea5GWmUyyZJ0ojra9BruMlPgIXMfFDDvj8ALgDOysy/bDr+tcAfZ+bd\nuylYP1Qy6EmSpEoaVB+9y4HfjogXlDe9M/Dy8rmPtTj+/sB3uimUJEmSureWGr3HAv9SPtxJMYXK\nnsDnMvOIpmOngO8C783MP+19cbtjjZ4kSRoXA6nRy8x/Bf4E+D7wqxQh7xPAU1scfiKwF/Dhbgol\nSZKk7q15rduICODXgRsy89o2x9ydIuhdPYpVZ9boSZKkcTGQwRhVYtCTJEnjYlCDMSRJkjSGDHqS\nJEkVZdCTJEmqKIOeJElSRRn0JEmSKsqgJ0mSVFEGPUmSpIoy6EmSJFXUbdZzUkTsAdyFYhWMljLz\nmvUWSpIkSd3rKOhFxOHAq4DfBW7X7jAggT26K5okSZK6seagFxHTwKeBPctdNaDlmrcUQW9dIuJl\nwAOBBwEbKNbN3bjC8fcDXgscUZbtP4BXZubF6y2DJElSFax5rduI+BRwFPB24NTM/GFfChSxC/gx\nRWB7MPDTzLxXm2PvDfw7cDPwBorg+XzgEOBxmfnppuNd61aSJI2FXqx120nQuw64Bjikn2kpIjZk\n5mL576uAvVcIeucDTwYelJlXlvvuAHwFuDEzD2o63qAnSZLGQi+CXiejbgO4st9JqR7yVi1MEeie\nCMzVQ155/s+AdwAHRsRD+lJISbubnYVabfm+Wq3YL0kaik6C3peBu/erIOtwKEWfvM+3eO4L5fbB\ngyuONOGmp2Hr1qWwV6sVj6enh1suSZpgnQS9NwCPiIjf7ldhOvQb5fY7LZ6r79tvQGWRNDUFMzNF\nuFtcLLYzM8V+SdJQrHnUbWZ+KCIOBj4REa8ELhzyXHl7l9ubWjx3Y9MxkgZhagpOPhk2boSFBUOe\nJA3Zmmv0ytGwWykmSv47YCEiftnup18FbnBDuW01n99eTcdIGoRaDbZvL0Le9u2799mTJA1Upytj\nRJt/D8N3y22r5tn6vt2adbdt23brvzdt2sSmTZt6XS5pMtX75NWba+vNuDbfStKazM3NMTc319Nr\nrnl6lWFYaXqViNgH+BEwn5m/1/TcqcDpwEMz84sN+51eReqX2dli4EVjqKvVYH4eNm8eXrkkaUwN\ndB69YVjjPHpPAR7YMI/ePhTz6P3cefQkSdK46kXQ67Tptu8i4pnAAeXDuwG3jYhXlI8XM/N9DYe/\nDHgUxQCR1wPXUayMcQ/AKgRJkjTRRq5GLyIuBo4sH9YLV0+zc5l5VNPxBwGvKc/ZE7gC2JaZn2lx\nbWv0JEnSWOhr021ELFAErUdl5kLD4zVp19w6TAY9SZI0LvrddFtvPr1t02NJkiSNgZWCXr1G7ttN\njyVJkjQGRq6PXj/ZdCtJksZFL5puO1nrVpIkSWPEoLeS2dndl3Cq1Yr9kiRJI86gt5Lp6WIJp3rY\nqy/xND093HJJVeQfVpLUcwa9lTSu17m46LqdUj/5h5Uk9ZyDMdZicRE2boSFBdiwodfFklRXD3cn\nnwzbt/uHlaSJ5mCMQajVil84CwvFtrlpSVLvTE0VIW/jxmJryJOkrhj0VlKvXZiZKWry6s24hj2p\nP/zDSpJ6as1NtxFxJPC9zPzaKscdCNw9My/pQfl6quOm29nZon9QY61CrQbz87B5c+8LKE2yxj+s\npqZ2fyxJE6ava922uNku4NzMfM4qx70DeHZm7tFNwfrBCZOlEeYfVpK0TL/Xuu1GV4WSNIFahbmp\nKUOeJHWhH330fg24oQ/XlSRJUgdWrNEr++UlSzV0d4+II1a41m8Bjwa+2rMSSpIkaV1W7KNX9str\nDHprtSUz39pNwfrBPnqSJGlcDKKPXuPI2SOAHwD/3ebYm4FvAx/OzI91UyhJkiR1r9NRt+/JzGf3\nt0j9Y42eJEkaF4MedXsU8L1ubiZJkqTBca1bSZKkEeRat5KWzM7uvmRYrVbslyRNpLZBLyJ2RcQv\nyyXNGh+v6WdwL0ESUKwq0bgWc30Jsenp4ZZLkjQ0q9XoNVcXRgc/kgZpaqpYF3brVlhcdJ1YSZJ9\n9KTKWVyEjRthYQE2bBh2aSRJ69TXPnoR8cSIeEA3F5cqY1z6v9VqsH17EfK2b9+9zJKkibJS0+1H\ngBfXH0TExRFxSv+LJI2gcej/Vi/TzExRk1dvxjXsSdLEWq2PXuPzRwIH9bEs0ugah/5v8/PLy1Qv\n8/z8cMslSRqatn30ImIn8J+Z+cjy8S7g3Mx8zgDL11P20RNQNLdOTy8PabVaEYg2b175XPu/SZIG\npN8rY1wOHBURfw98o9z3gIg4bS0XzsxXdVMwqW/qzbD12q/GJs+VNPd/G7UaPUmSmqxUo/cI4GPA\nndZx3czMPbopWD9Yo6db1cPdySevLbQ1hsHmcGjYkyT1QS9q9FacXiUi9gMeA+wPbAN2AB9dw3Uz\nM0/vpmD9YNDTMp00w3bT3CtJ0jr0Peg13WwX8J7MfHY3Nxwmg55u1WmNniRJAzbotW6fA7yjm5tV\n1rjMsTZoo/q+OA2JJGlCrDnoZea5mek8Da2MwxxrwzCq74vTkEiSJkTHS6BFxN2A51PMq7dfufs7\nwBzwjsz8US8L2Et9bbq1KbA13xdJktZloH30yhs+HjgP2LfNITXgGZn5L90Uql/63kfPOdZa831p\nzQEekqQVDLSPXkQcBPwDRci7DDieYkTuY4A/LfdNAReUx04W1xhtzfelvVFt2pYkVUYno27PBZ4F\nnJKZr2tzzEuA1wHvzcw/6VEZe6ZvNXrOsdaa78vqbNqWJLUx6OlVrgF+mpn3X+W4LwP7ZuZvdlOw\nfuhL0Judheuvh6OPXvoFXavBRRfBPvtMdhNcv5omq9bkadO2JKmFQU+v8usUEyav5svAr62vOGNo\nehouuWTpcb2G5uijRz90rDb9SbfTo2zevHvt1NRU9+/LsJo8+zFdjE3bkqQ+6iToXcfSKNuV3AO4\nfn3FGUP1qTm2bi1qZsapaXK1wDSqfcgG+Z43hrv6+3H11Uv7u3k/nM9PktRvmbmmH+DjwC3A765w\nzMOBXwAfX+t1B/lTvNw+WVjIhGK7HhdemLlz5/J9O3cW+/tp587MLVuKcm/Z0roMKz0/TN2+52tR\nf/311724mHnIIZk7dnT/fgzrv7kkaSyUuaW77LPmA2EzsAu4FjgDuDdwG2AP4D7Aq8rndgGbuy1Y\nP376FvR6EYaaA0Xz435aLTCtJVANOrQMMoA232vHjv4HTEnSxBto0Cvux6vLILcL+GVZw3dL+e/6\n/ld3W6h+/fQl6PUyoA2j9qxXNXqDDKrDCMX1sFuvyRvFGk5JUqUMPOgV9+TxwKeBGxvC3Y3Ap4DH\nd1ugfv70Jej1uiZrEM2RdasFpk4D1aCC6rBqD3fsKJptFxeX7zfsSZL6oBdBr5PpVe5U3vC68vFt\ngLuUT/84M3+xpgsNUd9XxujWoOdUW22akvVMY1K1qUIaB0zMz8Mhh8BZZy2fG3Bcp3WRJI20Qc+j\ntwu4PDN/p5sbDtNIB70qTC5cxcl/qzZnnyRpbAw66F0L/HNmPqObGw7TSAe9cQ8UVQiqkiSNkEEH\nvS8AP8/MTd3ccJhGOuiNu3EPqpIkjZhBB73nAucAh2fm5d3cdFgMepIkaVwMdAm0zHwn8BbgExHx\nlxFxYETcrpubq41+LLUlSZImzpqDXjkYYwswBfwV8F/ADRHxy1Y/fSrvZBjVpcckSdJY6XTU7Zpl\nZifr6A7EWDXdVnEEqyRJWrOB9tGrgrEKelC9OekkSdKaDbSPngasVitq8hYWim1zn71RZf9CSZJG\nxuQGvVEOH41z0G3YUGwb++yNMvsXSpI0Mjpuui1H2v4BcCRwz3L3d4A54B8z86ZeFrCXbm26HfXJ\nfMd9Tjr7F0qS1LWB99GLiGng/cD+bQ75NnBcZn62m0L1S0Rk1ptCDR/9Zf9CSZK6MtA+ehFxMHAR\nRcj7FjADvKD8+aty3z2Bj5fHjqaNG4uapmGHvCr3ZRvX/oWSJFVMJ330XgXsDbwGODAzT83Md5Q/\nrwDuRxH49i6PHU2jEj563ZdtVILjKPQvHJX3YtAm9XVLktrqJOhtAr6WmS/PzN3m1MvMXwKnAl+j\n6L83mkZlcMP8PJxySlGOxcVi++AHw0UXLT9urb+oR2UQxPz88mbxqani8fz84MowKu/FoE3q65Yk\ntdXJhMk3AB/OzONWOe79wJMy8w49KN9aytVuIuefZeYdm45dmkdv2IMb6r+Ejz8eDjsMduyAN76x\neO51rysCUqeDRhwEsWRS34tJfd2SVEEDHYwREV8CdmbmUasc9xngzpn5gG4KtlZl0LsEeFvTU7dk\n5gVNx47GhMn1UbU//Skccwy85S3wghfASSfBU57S3S/qcR4E0evRxuP8XnRjUl+3JFXMoCdMfgtw\nRET87goFmgaOAM7pplDr8K3MfH/TzwWrnjWs/kvT00WoO+MMOO88eMQj4P73h0svLZ4/+eT1DRoZ\n90EQvWx6HPf3Yr0m9XVLklrLzDX/AK8HrgfOAg4F7lj+HAq8FrgO+OtOrtntD7ALeDdwW2CfVY7N\n3LkzM7NsQYECAAAelUlEQVTYbtmy9HjQPvjBzGc8Y+nnuc/NXFws9m/Zkrmw0Fn5ml/PsF/fetXL\n3enrb3WNcX8vOjWpr1uSKqqIad3lpE6abncBCdSrEJtPbKxa3O2imbnHmm7UobJcPwP2AvYAfgR8\nCHhFZl7bdGzmli2j0X+pVoMXvQje976i9mVqqqjlg/X10eum2XPUJmjutulx1F7PoEzq65akihp0\nH712gx7WJDP7stxaRFwGnA98A7gTsBl4OvBl4OGZ+bOGY4sJk0eh/9KHPgSf/CS84hVLobM+4vbp\nT186bhC/qJsD5TBXDnEwgSRJQG+C3sCaWAf5A7yMokn35U37u28W7IVBNLFdeOHu19u5s9i/UpmG\n+d7Y9ChJ0q0YZNPtOImI21D0Jbw8M3+3YX++8qUvhb32ghtvZNNXv8qmc88dfI3RIJrY1lNLN+zR\nmjY9SpIm2NzcHHNzc7c+Pv300wfXdDtuImIBuCkzD2rYl8teb9VDRCfNoDaZSpI0UgbaR2+cRMRe\nFCOAL83MIxv2ZxVf74rWUks3Sn30JEkSMPh59EZORNy5zVNnUIzA/VjPbjaO64iudU61UVi2TJIk\n9dxY1+hFxOuBhwIXA/8D7AM8nmJd3suAR2bmTQ3Hr79Gb9xqvXpdXvvPSZI0UBPfdBsRTwS2AIcA\ndwF+CXyNYrqVv8nMm5uO767pdpz6sfU6mI1b0JUkacxNfNDrVE/66A17ZOowjVPQlSRpzE18H72B\nq8o6oq36G37oQ8VPo+Y+iFNT61+HV5IkDZxBr53mMFSrFUuUHXFEUZM3M1PUbo1b2JudhUMOWV72\nq6+Gd76zWKmjvq9eezc9vXRuN0F3HAezSJI05gx67UxPLw9D9eXJjj662I7ryNTpaTjrLDjllOL1\nXXklHHMMvP3txRq7W7cWzdPN/e8a++StJ+g2v5+tgqQkSeop++itpKp90uqv69hj4RGPgB074NBD\ni+fa9UFsNbij3tS71rV5q/p+SpLUB/bR67eq9ElrbjadmloKeZ/9LJxzTvH8Sk2zmzfv/vqPPhou\nuWTttXRVeT8lSRoTBr2VVGXwRXOz6ZVXwpOeVIS8D3ygaMY96aTip5Om2Xrzdbvm3mb9ej/t/ydJ\nUmuZOTE/xctdo507M7dsKbatHg/ThRfuXo6dO4v97dTLv2NH5gEHFNvG/e96V+YHP9jZNesWFjKh\n2K52/368n6P830qSpHUqc0t32afbC4zTT0dBbz1halDWG2zqgawe8uqvsfF1dfoa6/deWFi5DP1+\nP9daDkmSxkQvgt5kD8YY5yW8Oh3Y0Op46G61i1FbLWOSJ7OWJFWOgzHWoyrTe3QysKHd1CjQWR+7\nZvPzy48f5pQzVelPKUlSD01ejd6WLaM1vcd616TtpEZvtXuMe03YqNUsSpLUA65126GIyFxYGK1Q\ns56Q0stgU4W57dYbliVJGmEGvQ6tWqM3rMDQadjqVTmtCZMkaWQZ9DoUEZk7d7YPNcMMPsNoPrUm\nTJKkkeVgjPVYaeBAuwmA5+f7OyHvsAYStFrtYmrKkCdJUkVMXtBr1CrUtBrN2ryyRC9H7LYbEdtt\n2HO1CEmSJt5kB71WWtWuNdb0vetdS0uFNTb5rjdA9WuKkn6GU0mSNBYmr4/eSq93tT569X50mzbB\nuefCAQcsHXPKKXDVVaPV7FmFEbWSJE0o++j12kq1a401ffvvD497HFx55VLIO+uslWvLhtGU2smk\nypIkqXIMeo1aDU6Yn4dDDlnej+6MM+Cud4XDDoNjjy1C3mq1ZcNoSnW1CEmSJppNt6up1eC44+DN\nb15qqj3pJLjpJrj//eGlL4UdO+DQQ9d2rUE1pTpHniRJY8159Dq0rqAHywPamWcW+049tajJO/74\nIgheeGERBFczqPnynCNPkqSxZtDr0G5Br5PgUw9o73wnPOpRy5trr74aTjgB3ve+lWvLHBwhSZLW\nyMEY67GePnKNfd2uuAIuu2x5SDvggCLkrTQlSr/my5MkSWpj8mr0VlrrtpVe9XWzKVWSJHXAptsO\nRUTmwkJnfeQMaJIkaQhsul2PTqcbcT1YSZI0piavRm/nTqcbkSRJI88avfXo1Zqy613pYhgrZEiS\npIk0eUGvUTdNsOtd6WIYK2RIkqSJNHlNt718veudF8/59CRJ0iocdduhngc9WP9KF4NaIUOSJI0l\n++gNW+NEymsdxdvNeZIkSR0w6K3Xele6cIUMSZI0IJPXdFufXqVuvZMfr3ciZSdgliRJa2AfvQ7d\nugRa83JmRxwBRx9t+JIkSSPDPnrrUW8qXVxcakI9+minPJEkSZUzeUFvaqqY1mTjxmI7NVXU3J1y\nyvIAeMoprSdTbpzwuP7vD32o+IGlyY+dBFmSJA3Z5AW9ViNep6fhrLPg+OOLAHj88cXjVjV6jRMe\nT0/DSScVge6Tn4Srry6eO+QQawQlSdLQ2Uev3nz705/CMcfAW94CL3whXHghHHBA6ws1Tnh85pnF\nvhe/GI47Ds47D845x0mQJUlSVxyM0aG2o24vugguuaSoyTvsMNixY/Ww1jjhMRT//uxn4RGPcBJk\nSZLUNQdjrEdzcJuagn32KfrknXNOEdLOOad9Hz1Y3vx75pnFz44dRU3gjh1OgixJkkbC5AW9Vup9\n9BonMW7XR6+xubceGm++Gd74xqK5tx4SnQRZkiQN2eQ13bZ6vZ1MYtx4bP3fF11UPPf0py+dNz29\n8jx8TpwsSZJWYB+9DrUNesPQXDPYqqZQkiRNLPvojaLGefbqWs2pNzXVevJmQ54kSeoRa/R6rdOa\nusbRu47UlSRJJWv0RlEnNXWtJm+WJEnqEWv0+mW1mjr76EmSpBVYo9dPs7PF+rWNtWz1dW1XW8N2\nLTV18/PLQ129JrDd3H1rLfNa+gdKkqSJYI1eO7VasY4twOteV2wbH7erdRtmTZ21hJIkVYbTq3So\n46bbeti76abi8e1ut3LIA9i2DZ797OXr5F59Nbz73cVz/da4Du/27YY8SZLGlEGvQ+vqo1fvawdr\nGxk7CrVqjuSVJGnsGfQ6NJAavfp5w6pVs0ZPkqRKcDBGPzX20XvTm+CYY4o1bU86aWnAQ7uBDlNT\nRdDauLHYtgpa/Rg40Vh7WF+z1zV3JUmaWAa9VmZni/VrH/3opRq8ww+H739/aQ3beqiant79/LWM\nup2eXh7CVrreWvVjJK8kSRpbkxf0VqtJm52FQw6BSy6Bo48uwtLVV8MJJ8Db3w6XXw4HH9y+391a\na9X6sQTa5s27nz81VeyXJEkTZ/L66O3cufJgifrjU06Bs86C44+H446DCy8sRtLWBzrs2AGHHrp0\n8VptqeZsenp54Ko/1ypwOXBCkiS1YB+99VitJq3+/FlnwbHHwmGHwXnnFSGv3iS7Y0cR/q6+ujin\nsdm1k1o1l0CTJEl9NHk1evXXu1pN2pVXFiHvs5+FD3xgqYavHgqvvroYoHHeeXDOOZ03u47CNCyS\nJGlkTXyNXkT8SkT8RUR8NSJ+HhHXRMTrImLvFU9crSbt6quLGrsdO5ZC3gknFNt6CDvggCLkHXZY\n+5G1K2k3cOINb3AZM0mS1BNjHfSA1wN/DVwF/BlwAfBi4GMR0ToB12vOjjhieTNurba0lu2WLUWf\nvEMPXWrGPftsuOqq5dc555z1N7u2a+I98cTej8aVJEkTaWybbiPiYODLwD9m5lMb9v8Z8EbguMz8\nQNM5mRdeuBSa6k2lUEyncsklRQCsj7adnV06tj6YolZbOrZfza7jPOlx/T1b62AUSZLU0kSvjBER\nZwIvBx6RmfMN+28H/Bj4t8zc3HTO8pUxVgtU7frRNYbBxmN7GWbGdTSufQ8lSeqJSQ96FwFHAXtn\n5i1Nz80D983MX2vav/sSaKsFqmHUro1zjR6Mf/klSRoBkx70vgzcNTPv0eK584E/BPbMzF807O+s\nRq9ukLVrVakRG9caSUmSRsSkj7rdG7ipzXM3NhzT2lpXsBj0XHdVWMbM+QElSRoJVa7R+wPgds01\neq985SuLB1/7Gpv+6I/YdMwxSyc297OrSu3aIPmeSZK0LnNzc8zNzd36+PTTT5/optvV+ujdJzN/\nvWn/7n30VuII0s75nkmS1BOT3kfvDGArcERmfq5h/14Uo27nVh11K0mSNKImvY/eh4AETmza/3zg\n9sB5Ay+RJEnSCBnbGj2AiHgjxYoYHwY+Dvwf4EXA5zLzqBbHW6MnSZLGwkQ33UKx1i1Fjd4LgA3A\njyhq+k7LzBtaHG/QkyRJY2Hig16nDHqSJGlcTHofPUmSJK1gMoPe7GzriZFnZ4dTHkmSpD6YzKA3\nPb18FYz6pL7T08MtlyRJUg9Nbh+9ta5zK0mSNAQOxujQboMxFhdh48ZiTdYNG4ZVLEmSpN04GKMb\ntVpRk7ewUGyb++xJkiSNuckMevVm25mZoiZvZmZ5nz1JkqQKmMym29nZYuBFY5+8Wg3m52Hz5vYX\nkCRJGhD76HXICZMlSdK4sI9et5xPT5IkVdhkBz3n05MkSRVm063z6UmSpBFkH70Ote2jN4z59BwQ\nIkmSVmAfvV4Y1nx6NhtLkqQ+m+wavcb59Kamdn/cbzYbS5KkNmy67dBuQW8Umk9dhk2SJLVg0223\nNm/evQZtampwIc9l2CRJUh9NdtAbJpdhkyRJfTbZTbfDNArNxpIkaWTZR69DIxX0JEmSVmAfPUmS\nJLVl0JMkSaoog54kSVJFGfQkSZIqyqAnSZJUUQY9SZKkijLoSZIkVZRBT5IkqaIMepIkSRVl0JMk\nSaqoyQ16tVqx3qwkSVJFTWbQq9Vg61aYnh52SSRJkvrmNsMuwMAtLsL27TAzA1NTwy6NJElS30Rm\nDrsMAxMRxatdWIANG4ZcGkmSpPYigsyMbq4xeU23CwtFjV6tNuySSJIk9dXk1ehlLvXRs/lWkiSN\nqF7U6E1m0IMi7M3Pw+bNwy2UJElSCwa9Di0LepIkSSPMPnqSJElqy6AnSZJUUQY9SZKkijLoSZIk\nVZRBT5IkqaIMepIkSRVl0JMkSaoog54kSVJFGfQkSZIqyqAnSZJUUQY9SZKkijLoSZIkVZRBT5Ik\nqaIMepIkSRVl0JMkSaoog54kSVJFGfQkSZIqyqAnSZJUUQY9SZKkijLoSZIkVZRBT5IkqaIMepIk\nSRVl0JMkSaqosQ56EbEYEbva/Nx52OWTJEkaptsMuwBdSuC/gJkWz10/4LJIkiSNlHEPegH8IDPf\nP+yCSJIkjZqxbrotRUTsERF3GnZBVC1zc3PDLoLGhJ8VdcLPiwapCkHvocANQC0idkbEuRFxj2EX\nSuPPL2OtlZ8VdcLPiwZp3JturwIupeind1vgkcDzgEdFxO9k5veGWThJkqRhGnrQi4h9gb/o4JS/\nzcydAJl5TNNz50fEJcB5wOnAC3pTSkmSpPETmTncAkRsAL5FMYI2Vjk8gftm5rdWueYCsGdm7te0\nf7gvVpIkqQOZuVo2WtHQa/Qyc5He9xVcBB7W4l5dvVmSJEnjpAqDMVq5D/CDYRdCkiRpmMY26EXE\nr7bZfwKwH/CxwZZIkiRptAy9j956RcSJwHOBjwNXUzRDbwKeBHwDeFhm/nhoBZQkSRqycQ56Dwde\nCjwAuBvFQI5vAR8FXpOZ1w6xeJIkSUM3tk23mXlpZj4pMw/IzL0z8/aZeXBmvrwx5EXErjY/1w2z\n/BqeiHhZRFwQEd8qPwsLqxx/v4j4SET8JCKuj4hLIuKRgyqvhquTz0tEbFvhO+clgyy3Bi8iDoyI\nV0XEZRHxw4i4NiK+FBEvj4i9Wxzvd8uE6uSz0u33ytBH3Q7IJcDbmvbdMoyCaCTMAD8G/gPYl2La\nnpYi4t4Uk3LfDLwWuBZ4PnBRRDwuMz/d/+JqyNb8eWlwIvC/Tfuu6HG5NHqeA2yhaFn6e4rfM0cB\nZwJPi4jDM/NG8LtFa/+sNFjX98qkBL1vZeb7h10IjYx7ldP6EBFXAbv9pd3g1cCdgAdl5pXlOe8F\nvgKcDRzU36JqBHTyean7SGZe09dSaRRdAMxkZmOL0dsi4uvAVop+5WeX+/1umWydfFbq1vW9MrZN\ntx2KiLhtROwz7IJo+Oq/tFcTEXcAngjM1b+Iy/N/BrwDODAiHtKXQmpkrPXz0iQi4k4RMSl/TAvI\nzCuafnHXnV9uDwa/W7T2z0qTdX2vTErQ+0PgBuDaiPhBRLwxIu407EJp5B0K7Al8vsVzXyi3Dx5c\ncTRGrgRqwM8jYj4iHjvsAmmo7llu6/O7+t2idpo/K43W9b0yCX9t/jtFQv4GRTX5ZuDPgCMj4uHl\nX1BSK79Rbr/T4rn6vv1aPKfJtRM4h6Lv1U6K5rcTgdmIeE5mvmeYhdPgRcQewKkUfbDqXYj8btFu\n2nxWoMvvlcoHvcw8vGnX+yLiSooO1n8O/NXgS6UxUe+LdVOL525sOkYiM/+2adeFEfEu4Crg9RHx\nD/5xOXHeABwOvCwzv17u87tFrbT6rHT9vTIpTbfNtlOMdHr8sAuikXZDub1di+f2ajpGaikzfwK8\nFZgCHj7k4miAIuIM4ATgnMx8bcNTfrdomRU+Ky118r0ykUEvM38BfA+467DLopH23XLbqgmlvq9V\n04vU7Opye5ehlkIDExHbKEZPviszX9j0tN8tutUqn5WVrOl7ZSKDXkTsRdHhsVVnR6nuyxRNK63+\nWqp3Cbh8cMXRGLtvufU7ZwKUv7hPA87NzOe1OMTvFgFr+qysZE3fK5UOehFx5zZPnQHsAXxsgMXR\nmMnM6yk+I5si4tD6/nKanucBX8vMLw6rfBotEbFHROzbYv/+wAspJjq9dOAF00BFxGkUv7jfm5nP\naXWM3y2CtX1WevG9UvXBGKdGxEOBi4H/Afah6Je3CbgMeNPwiqZhiYhnAgeUD+8G3DYiXlE+XszM\n9zUc/jLgUcAnIuL1wHUUs9ffg2IEtyqug8/LHYGFiPgw8FWK0XH3o/jFvTdwbGa26nyvioiIE4Bt\nwDXApyPiGU2HfD8zP1X+2++WCdbBZ6Xr75XIXMtqPuMpIp5IscTIIRRt2L8EvkYx3crfZObNQyye\nhiQiLgaOLB/W/weIcjuXmUc1HX8Q8JrynD0plpzZlpmfGUBxNWRr/bxExJ4UM9k/lKJryD7Aj4B5\n4KzMtCmu4iLi3cCz6g9bHLLs+8Xvlsm11s9KL75XKh30JEmSJlml++hJkiRNMoOeJElSRRn0JEmS\nKsqgJ0mSVFEGPUmSpIoy6EmSJFWUQU+SJKmiDHqSJEkVZdCTNBYi4k8iYlc5o/yg7rkrInYN6n6d\niohNZRkvHtD9HhgRp0TE+RGxUH9/IuJBazj3VyLihIi4PCKuj4haRFwSEf+3zfEbymsv9P6VSJPD\noCdp3PRkOZ+IOLcMEn88iPv1STZt++00iiW7/hD4zYZ7r3j/iNgD+DDF+uL3Bv4V+CzwEOD9EfGG\nFU4f5fdfGnm3GXYBJGnIVgoSBw2sFOvz7xRlvGFA97sU2EGxJusVFOtt/uaKZxROBJ4AfAU4KjN/\nBBAR96EIfC+OiM9k5j/3pdTSBDPoSZp0rRYUByAzvzbIgnQqM38ODKyMmXlW4+OIgLXV5p1SHvfC\nesgrr/eNiHgpcC6wFTDoST1m061UIY19yiLiBRHxpYi4ISJ+HBH/GBEHr3DuARHx5oj4VkTcFBE/\niYjPRMSxbY7fVt7vlRGxMSLeFxE/iIgbI+KqiHhJ+Uu++bwVm0wbr9vB6/6DiHhXRHyl7Pt1Y0R8\nIyL+LiLu2XTshvI9ela5690Nfc2WlWulPnoRcdeIeG1EfDUifh4RP42Iz0fEC9u87lv7GEbEPhGx\nvezndlNEfKd87391ra+5vGbLPnrN/dsiYktE/Gf5WdgZER9Z6bPQYw8D7gZ8OzM/1+L5C4BfAA+O\niN9YywUjYt/ys7krIv4pIvbqYXmlSjHoSdWTEfF64M3AToq+UT8Cngx8ISKmm0+IiMOB/wT+FNgF\n/CPwRWAaOC8i3rPC/TYClwNHAp8BPg3cC3gdcEGU1T6tyrna61jl+UYfoug3dh3wCeAiYE9gC/Af\nEXHfhmOvA94DfLN8/DmKGqX6z9dXK0fZ5PgfwMnAHYGPAv8G3B84G/h4ROzZpqz7UjSBPru8xr8C\nt6d47z8ZEetpaWn7XpX/7f4a+D7wMaAGPBGYj4iN67hXp3673H6x1ZNlreRXKGpWH7DaxSJif4r/\nZpuAszPzKZl5Y2+KKlWPTbdS9QTwfGBTYw1KRPwV8JcUnd8PzMybyv17AedTBJDXAydlZpbPHUwR\n3J4ZEfOZ+bYW93sW8A/AMzLz5vK8+wAXA79PEWDe0pdXuuT/Ahc2/sIva9VeCbwC+Fvg8QCZ+WPg\n2RFxLsXAgHdk5ns7vN/7gXtSvG/Panjd9wQ+BfwesA14eYtzfx+YBQ7PzBvK8+4BXAY8EHhaef1e\nOIAirP9WZtZr9/YE/oni/XgZ8IIe3audepi8eoVjrgEOAzasdKGIOAz4F+DXgVMy83W9KKBUZdbo\nSdX05hbNZK8AvgXsD/xBw/6nUoSWBYpfnrfWDmXmVyjCEsBJbe71M2BLPeyU530DOLV8+BfrfRFr\nlZn/0Fyrk5m/zMzTgO8Bj46IO/TiXhHxCODBwLXAnza97m8Df14+PCEibtfiEtcBz62HvPK87wF/\nVz48qhflrF8aeHE95JX3uhk4vQ/3amefcvuzFY65vtzesd0BEfEYioEbdwb+yJAnrY1BT6qeBN63\n287MXcAHyoebGp46sty+PzN/2eJ655bbe7fpQ/XJzPzfFvvfX5al3Xk9FREHRsSLI+KNZX+9c8ta\nuz3Kn/v06Fb19+tjmVlrfjIzL6JoJt0HaDW/3BWZ+cMW+/+73PbyvfoFRdPwIO7VNxHxbIpa0FuA\nx2Tm+UMukjQ2bLqVqqndJLP15rP9GvbV/93ynMy8KSK+C9yDIhh8dy33ysybI+J75Xn7tTivJ8o+\nbW8GnteqGCyNqr1Tj2654vtV+hZwd1oHqWvanHNtue3lwILvlQF/mcy8tuw62arGsdfqtXUr1ajW\na/2ua/Hc/sA7KfqOPjYzW/b1k9SaNXqS6kZlYtpOv5f+nCLkfQd4OkUwuF1m/kpm7kHR9w1WmEZl\nndb7fg1ypY1RWNVjsdwesMIx+zcd2+iHwMcpPhd/GxH79qxk0gQw6EnV1G405YZy+52GffV/37vV\nCeVgjd9oOnbVe5Wd/u/R4rx6n7Z9aG2lQNDKU8vt8Zl5QWZ+JzNvaXi+V022dd8uty3fr9K9ym2r\n92vSXFFuH9LqyYjYGziEIjh/qcUhNwFPAj4CHA58JiLu3IdySpVk0JOqJ4DjdttZjEKtrys61/BU\n/d/Htpr/DajPK/eNctBAs8dExF1a7D+2LMs3M7Ox2bYelP5PizLenuX9B9fizhQh4dvNT0TEo4G7\n0rr2rR44O+3C8m/l9gkRMdXinkdTNNtex1LImWSfp5jeZ/9yIEuzp1L8N/him88XmfmL8rgPUEzX\nMhcRv9an8kqVYtCTqmlL43x55Vx2p1PUNH2bYp68uguA/6GomXt147x3EfFbLI3QbDfKcW/g7MZ5\n4yLi3sAZ5cO/bTr+0+X2mRFxYMM5t6eYhmV/OvNfFIHyhU1lvzfw1vrDFufVg+FvdXKzcjTzFylG\niDa/7v2A+rqtf9c4IrfiVlpdZBdQX1HjLRFxt1tPKuY3fA1FEJ9Z6QblQKFnAO+iqAG8pHy/Ja3A\nwRhSNb0N+LeIuIRiBOgDgQMp1kQ9rj6HHtw62OJpFP2gTgKeHBGXU9SUPZJixOp7M/Ptbe7198Bm\n4JsRcSlFAHokRUf/f87MsxsPzsz5iLgQOIZiMuPPUa6MUG7fTTGZ8Fq9GngscDzwyIj4z7LsR1BM\nTPw94OEtzvsocBpwYkTcnyL4JfDOzPz8Kvf8I4p5Ao8FNpWvYe/yde9NMZfetg5ew1iIiM0sTZsD\nRc1lAOdGRH36lO9m5lOaTn09xX+PJwBfj4jPALelmG9wT+BNmfmx1e5fTv3zvIi4AfgzirD3qMxc\n7OJlSZVmjZ5UPZmZ/w94EUXgeRJF8+WHgYdm5mdbnPAFilUJ3koR7J5M0adqnmIi5D9Z4X7fLI+t\nr1bwSIpRpyezfL6+Rk+lqMn5YXnOAyhWbXggxajUVk2tLQc/ZOZl5f1nKUbWPoGiT+GZFAHwllbn\nZuYOisEbX6To+/Xs8ue+zce2OPebFE2I2ymaaJ9IEWS+DJwAPK6pn2Db8nfwfK/O6cZdgd+heL8f\nQhHWkqJWtL5vt9Utylq936f4TH4DeAzwCIr3/rjMPLGTQmTmiylqCTdS/EHT636YUmVEw9yoksZc\nFOuyZjnatN/32kZRI7YtM1/V7/tJkjpnjZ4kSVJFGfQkSZIqyqAnab2S0ZlkWZLUgn30JEmSKsoa\nPUmSpIoy6EmSJFWUQU+SJKmiDHqSJEkVZdCTJEmqqP8PWa5v5vqQ4rIAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x103742d10>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply Gradient Descent\n",
      "\n",
      "First write a function for the cost function.  The linear function cost function is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cost(X, y, theta):\n",
      "    m = len(y) # size of training set\n",
      "    return (1.0/(2*m)) * np.sum(np.power(X*theta - y,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the initial step, we assign \n",
      "\n",
      "\\begin{align}\n",
      "{\\bf \\theta} = \n",
      "\\left(\n",
      "\\begin{array}{c}\n",
      "0 \\\\ \n",
      "0 \\\\ \n",
      "\\end{array}\n",
      "\\right)\n",
      "\\end{align}\n",
      "\n",
      "compute the intial value (should be 37.02 according to notes)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "theta = np.matrix([[0.0],[0.0]])\n",
      "theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "matrix([[ 0.],\n",
        "        [ 0.]])"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j0 = cost(X, y, theta)\n",
      "j0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "32.072733877455654"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we implement a function to apply gradient descent to find the $\\bf \\theta$ that minimized the cost fuction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.asmatrix(np.sum(np.asarray(X*theta - y)*np.asarray(X), axis=0)).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "matrix([[ -566.3961],\n",
        "        [-6336.8984]])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = X*theta - y\n",
      "e.T.shape, X.shape, (e.T*X).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "((1, 97), (97, 2), (1, 2))"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gradient_descent(X, y, theta, alpha, N):\n",
      "    m = len(y)\n",
      "    J = np.zeros(N)\n",
      "    \n",
      "    # interate\n",
      "    for n in np.arange(N):\n",
      "        # compute cost for this iteration\n",
      "        J[n] = cost(X, y, theta)\n",
      "        \n",
      "        # iterate theta       \n",
      "        d = (X*theta - y).T*X\n",
      "        theta = theta - (alpha/m)*d.T\n",
      "            \n",
      "    return (theta, J)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Apply Gradient Descent for 1500 iterations and $\\alpha = 0.01$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N     = 1500\n",
      "alpha = 0.01\n",
      "(theta, J) = gradient_descent(X, y, theta, alpha, N)\n",
      "theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "matrix([[-3.8741],\n",
        "        [ 1.1909]])"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot the cost function versus iteration to ensure it converges:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(np.arange(N), J)\n",
      "plt.ylabel('J($\\theta$)')\n",
      "plt.xlabel('iteration')\n",
      "plt.axis([0, 1500, 4, 8])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "plot the fitted value against the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = np.asarray(theta)[0]\n",
      "m = np.asarray(theta)[1]\n",
      "h = m*np.asarray(x) + b\n",
      "\n",
      "plt.plot(x, y, 'rx')\n",
      "plt.plot(x, h, 'b-')\n",
      "plt.plot()\n",
      "plt.ylabel('profit in $10k')\n",
      "plt.xlabel('population in 10k')\n",
      "plt.legend(['Training data', 'fit via grad descent'], loc='lower right')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Visualize $J(\\theta)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "compute $J(\\theta)$ over the parameter space of ${\\bf \\theta}$ and visualize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# grid of theta values\n",
      "theta0 = np.linspace(-10, 10, 100)\n",
      "theta1 = np.linspace(-1 ,  4, 100)\n",
      "\n",
      "# computer J for each (theta0, theta1) pair\n",
      "J = np.zeros((len(theta0), len(theta1)))\n",
      "for i, t0 in enumerate(theta0):\n",
      "    for j, t1 in enumerate(theta1):\n",
      "        t = np.matrix([[t0],[t1]])\n",
      "        J[i,j] = cost(X, y, t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.mplot3d import axes3d\n",
      "from matplotlib import cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "ax = fig.gca(projection='3d')\n",
      "ax.plot_surface(theta0, theta1, J)\n",
      "ax.set_xlabel('$\\\\theta_0$')\n",
      "ax.set_ylabel('$\\\\theta_1$')\n",
      "ax.set_zlabel('$J(\\\\theta)$')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.contour(theta0, theta1, J.T, levels=np.logspace(-2, 3, 20))\n",
      "plt.plot(theta[0], theta[1], 'rx', markersize=10, linewidth=2)\n",
      "plt.xlabel('$\\\\theta_0$')\n",
      "plt.ylabel('$\\\\theta_1$')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}